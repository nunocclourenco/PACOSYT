{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import shutil\n",
    "import pandas as pd\n",
    "import zipfile\n",
    "\n",
    "from em import COLUMNS_6P, compute_all_lq"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loads the ALL SRIs to a pandas dataframe and saves CSV datasets for the diferente modelling strategies\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def line_split(line):\n",
    "    return re.findall(r'[^\"\\s]\\S*|\".+?\"', line)\n",
    "\n",
    "def load(zip_file, folder, manifest_fname, names):\n",
    "    \n",
    "    df = pd.read_csv( zip_file.open(manifest_fname), \n",
    "                     sep=\" \",index_col=0,\n",
    "                     names=names, engine=\"python\")\n",
    "    points = {'ID':[]}\n",
    "    for index, row in df.iterrows():\n",
    "        freq_lines = []\n",
    "\n",
    "        with zip_file.open(folder + \"/\" + str(int(index),) +\".sri\") as fi1e:\n",
    "            freq_idx = 0;\n",
    "            points['ID'].append(index)\n",
    "            for line in fi1e:\n",
    "                line = line.decode().strip()\n",
    "                if line.startswith('#') or line.startswith('!'): continue \n",
    "                token = line.split()\n",
    "                values = [float(x) for x in token]\n",
    "\n",
    "                if len(token) == len(COLUMNS_6P): \n",
    "                    for i in range(len(COLUMNS_6P)):\n",
    "                        key = COLUMNS_6P[i]+\"_\"+str(freq_idx)\n",
    "                        if key not in points: points[key] = []\n",
    "                        points[key].append(values[i])\n",
    "                else:\n",
    "                    print(\"Invalid header!\") \n",
    "                freq_idx = freq_idx + 1\n",
    "\n",
    "    return (pd.concat((df, pd.DataFrame(points).set_index(\"ID\")), axis=1 ), freq_idx)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "names_inputs=['ID', 'Np', 'Ns', 'Dinp', 'Dins', 'Wp', 'Ws']\n",
    "names_all=['ID', 'Np', 'Ns', 'Dinp', 'Dins', 'Wp', 'Ws', 'SRFp', 'SRFs']\n",
    "\n",
    "data_folder = '../data/transf_65nm/'\n",
    "\n",
    "''' Key labels (np, ns, subspace\n",
    "    \"balun\" : dinp < dins + 2*ns*ws + 4*(ns-1))\n",
    "    \"close\" : dinp > dins + 2*ns*ws + 4*(ns-1)) + 2\n",
    "'''\n",
    "\n",
    "data_files = {\n",
    "       (1,1, \"\"): \"../data/transf_65nm_1_1T.zip\", \n",
    "       (1,1, \"_balun\"): \"../data/transf_65nm_1_1T_balun.zip\", \n",
    "       (1,2, \"\"): \"../data/transf_65nm_1_2T.zip\", \n",
    "       (2,1, \"\"): \"../data/transf_65nm_2_1T.zip\" \n",
    "}\n",
    "\n",
    "\n",
    "if os.path.exists(data_folder): \n",
    "    shutil.rmtree(data_folder)\n",
    "os.mkdir(data_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = {}\n",
    "\n",
    "for file_key, filename in data_files.items():\n",
    "    zf_data = zipfile.ZipFile(filename,  mode=\"r\")\n",
    "    trans_sub_space = f\"{file_key[0]}_{file_key[1]}T{file_key[2]}\"\n",
    "\n",
    "\n",
    "    transf_TEST, freq_points = load(zf_data, f\"transf_65nm_{trans_sub_space}/transf_test\",\n",
    "                manifest_fname= f\"transf_65nm_{trans_sub_space}/input_samples_test.in\",\n",
    "                names = names_inputs)\n",
    "\n",
    "    transf_TRAIN, freq_points = load(zf_data, f\"transf_65nm_{trans_sub_space}/transf_training\",\n",
    "                manifest_fname= f\"transf_65nm_{trans_sub_space}/input_samples_training.in\",\n",
    "                names = names_inputs)\n",
    "    \n",
    "    \n",
    "    transf_TEST['SRFp'] = [200e9]*len(transf_TEST) \n",
    "    transf_TEST['SRFs'] = [200e9]*len(transf_TEST) \n",
    "    transf_TRAIN['SRFp'] = [200e9]*len(transf_TRAIN) \n",
    "    transf_TRAIN['SRFs'] = [200e9]*len(transf_TRAIN) \n",
    "\n",
    "\n",
    "    \n",
    "    lq_test = [None for i in range(freq_points)]\n",
    "    lq_train = [None for i in range(freq_points)]\n",
    "\n",
    "\n",
    "    for i, f in enumerate(range(freq_points)):\n",
    "        c = [col+\"_\"+str(f) for col in COLUMNS_6P] \n",
    "            \n",
    "        lq_test[i] =  compute_all_lq(transf_TEST[c[0]].values,transf_TEST[c[1:]].values)\n",
    "        lq_train[i] =  compute_all_lq(transf_TRAIN[c[0]].values,transf_TRAIN[c[1:]].values)\n",
    "\n",
    "\n",
    "    for r, (index, row) in enumerate(transf_TEST.iterrows()):\n",
    "        l_prev = lq_test[0][r,0]\n",
    "        for i, f in enumerate(range(freq_points)):\n",
    "            l_curr = lq_test[i][r,0]\n",
    "            if l_prev > 0 and l_curr < 0:\n",
    "                transf_TEST.loc[index, 'SRFp'] = (transf_TEST.loc[index, 'freq_'+str(i)] + transf_TEST.loc[index, 'freq_'+str(i-1)])/2\n",
    "                break\n",
    "        l_prev = lq_test[0][r,2]\n",
    "        for i, f in enumerate(range(freq_points)):\n",
    "            l_curr = lq_test[i][r,2]\n",
    "            if l_prev > 0 and l_curr < 0:\n",
    "                transf_TEST.loc[index, 'SRFs'] = (transf_TEST.loc[index, 'freq_'+str(i)] + transf_TEST.loc[index, 'freq_'+str(i-1)])/2\n",
    "                break\n",
    "\n",
    "    for r, (index, row) in enumerate(transf_TRAIN.iterrows()):\n",
    "        l_prev = lq_train[0][r,0]\n",
    "        for i, f in enumerate(range(freq_points)):\n",
    "            l_curr = lq_train[i][r,0]\n",
    "            if l_prev > 0 and l_curr < 0:\n",
    "                transf_TRAIN.loc[index, 'SRFp'] = (transf_TRAIN.loc[index, 'freq_'+str(i)] + transf_TRAIN.loc[index, 'freq_'+str(i-1)])/2\n",
    "                break\n",
    "        l_prev = lq_train[0][r,2]\n",
    "        for i, f in enumerate(range(freq_points)):\n",
    "            l_curr = lq_train[i][r,2]\n",
    "            if l_prev > 0 and l_curr < 0:\n",
    "                transf_TRAIN.loc[index, 'SRFs'] = (transf_TRAIN.loc[index, 'freq_'+str(i)] + transf_TRAIN.loc[index, 'freq_'+str(i-1)])/2\n",
    "                break\n",
    "    \n",
    "    \n",
    "    dataset[file_key] = (transf_TRAIN, transf_TEST)\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#one file per mode per freq\n",
    "dfs_train = [[] for i in range(freq_points)]\n",
    "dfs_test = [[] for i in range(freq_points)]\n",
    "save_data = True\n",
    "\n",
    "for file_key in data_files.keys():\n",
    "    transf_nturn_TRAIN, transf_nturn_TEST = dataset[file_key]\n",
    "    trans_sub_space = f\"{file_key[0]}_{file_key[1]}T{file_key[2]}\"\n",
    "\n",
    "    zf_test = zipfile.ZipFile(data_folder + f'test_dataset_{trans_sub_space}.csv.zip',  mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n",
    "    zf_train = zipfile.ZipFile(data_folder + f'train_dataset_{trans_sub_space}.csv.zip',  mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "\n",
    "    for i, f in enumerate(range(freq_points)):\n",
    "        c = names_all[1:] + [col+\"_\"+str(f) for col in COLUMNS_6P] \n",
    "        \n",
    "        transf_TRAIN_2 = transf_nturn_TRAIN[c]\n",
    "        transf_TEST_2 = transf_nturn_TEST[c]\n",
    "\n",
    "        rm = {}\n",
    "        for col in COLUMNS_6P:\n",
    "            rm[col+\"_\"+str(f)] = col\n",
    "        \n",
    "\n",
    "        transf_TRAIN_2 = transf_TRAIN_2.rename(columns=rm)\n",
    "\n",
    "        transf_TEST_2 = transf_TEST_2.rename(columns=rm)\n",
    "\n",
    "        dfs_train[i].append(transf_TRAIN_2)\n",
    "        dfs_test[i].append(transf_TEST_2)\n",
    "\n",
    "        if save_data :\n",
    "            zf_test.writestr(\"test_dataset_\"+str(f)+\".csv\", transf_TEST_2.to_csv())\n",
    "            zf_train.writestr(\"training_dataset_\"+str(f)+\".csv\", transf_TRAIN_2.to_csv())\n",
    "\n",
    "    if save_data :\n",
    "        zf_test.close()\n",
    "        zf_train.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# One file per frequency\n",
    "save_data = True\n",
    "\n",
    "if save_data :\n",
    "    zf_test = zipfile.ZipFile(data_folder + f'test_dataset_allT.csv.zip',  mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n",
    "    zf_train = zipfile.ZipFile(data_folder + f'train_dataset_allT.csv.zip',  mode=\"w\", compression=zipfile.ZIP_DEFLATED)\n",
    "\n",
    "df_allT_train = [None]*freq_points\n",
    "df_allT_test = [None]*freq_points\n",
    "\n",
    "for i, f in enumerate(range(freq_points)):\n",
    "    df_allT_train[i] = pd.concat(dfs_train[i],keys=range(1,6))\n",
    "    if save_data :\n",
    "        zf_train.writestr(\"training_dataset_\"+str(f)+\".csv\", df_allT_train[i].to_csv())\n",
    "\n",
    "\n",
    "    df_allT_test[i] = pd.concat(dfs_test[i],keys=range(1,9))\n",
    "    if save_data :\n",
    "        zf_test.writestr(\"test_dataset_\"+str(f)+\".csv\", df_allT_test[i] .to_csv())\n",
    "\n",
    "if save_data :\n",
    "    zf_test.close()\n",
    "    zf_train.close()\n",
    "\n",
    "\n",
    "\n",
    "# One with all \n",
    "df_allFT = pd.concat(df_allT_train,keys=range(freq_points))\n",
    "df_allFT.to_csv(data_folder + 'train_dataset_allTF.csv.zip')\n",
    "\n",
    "\n",
    "df_allFT = pd.concat(df_allT_test,keys=range(freq_points))\n",
    "df_allFT.to_csv(data_folder + 'test_dataset_allTF.csv.zip')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Copyright (C) 2022 Instituto de Telecomunicações & IMSE CSIC"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e5760e712c30506cacfbb8d55a91dfa6d917c7cae71b450333e4dc838792f2f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
