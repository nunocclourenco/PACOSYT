{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sklearn.gaussian_process.kernels as kl\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import em \n",
    "import models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inductor Guard Ring (GR) 0.35um \n",
    "\n",
    "\n",
    "<img src=\"../img/ind.png\" alt=\"drawing\" width=\"200\"/> \n",
    "\n",
    "\n",
    "Octagonal inductor in AMS 350 um.\n",
    "\n",
    "\n",
    "Before running this notebook make sure to [prepare](data_prepare_tmtt_indGR.ipynb) the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class PreProcess():\n",
    "    def __init__(self, model, whitening = False, standardize = False) -> None:\n",
    "        self.model = model\n",
    "        self.x_scaler = StandardScaler() if standardize else None\n",
    "        self.pca = PCA(whiten=True) if whitening else None\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        if self.pca:\n",
    "            self.x_mean = np.mean(x_train, axis=0)\n",
    "            x_train = x_train - self.x_mean\n",
    "            x_train = self.pca.fit_transform(x_train)\n",
    "        elif self.x_scaler:\n",
    "            x_train = self.x_scaler.fit_transform(x_train)\n",
    "\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.pca:\n",
    "            x = x - self.x_mean\n",
    "            x = self.pca.transform(x)\n",
    "        elif self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        \n",
    "        return self.model.predict(x)\n",
    "\n",
    "class RBFInterpolatorModel:\n",
    "    def __init__(self, degree=1) -> None:\n",
    "        self.degree = degree\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = RBFInterpolator(x_train, y_train, \n",
    "                     degree=self.degree, smoothing=0.00000001, neighbors=4000)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GaussianProcessRegressorModel:\n",
    "    def __init__(self, kernel) -> None:\n",
    "        self.model = GaussianProcessRegressor(kernel=kernel, alpha=1e-8)\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "\n",
    "class NearestNDInterpolatorModel:\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = NearestNDInterpolator(x_train, y_train)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model(x_test)\n",
    "\n",
    "class ANNModel:\n",
    "    def __init__(self, layers = None, degree = 5) -> None:\n",
    "       \n",
    "        self.poly     = PolynomialFeatures(degree)\n",
    "        self.x_scaler = StandardScaler()\n",
    "        self.y_scaler = StandardScaler()\n",
    "        self.layers = layers if layers else [256, 512]\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_t = self.poly.fit_transform(x_train)  \n",
    "        x_t = self.x_scaler.fit_transform(x_t)\n",
    "\n",
    "        y_t = self.y_scaler.fit_transform(y_train)\n",
    "\n",
    "        activation = 'relu'\n",
    "        output='linear'\n",
    "        epochs = 1000\n",
    "        loss=\"mse\" \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "\n",
    "        inputs = keras.Input(shape=(x_t.shape[1],), name='parameters')\n",
    "        \n",
    "        lay = inputs\n",
    "\n",
    "        for n in self.layers:\n",
    "            lay = keras.layers.Dense(n, activation=activation, \n",
    "               kernel_regularizer=keras.regularizers.L2(0.000001), \n",
    "               activity_regularizer=keras.regularizers.L2(0.001))(lay)\n",
    "\n",
    "        outputs = keras.layers.Dense(y_t.shape[1], activation=output, \n",
    "            kernel_regularizer=keras.regularizers.L2(0.000001))(lay)\n",
    "        \n",
    "        self.model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        self.model.compile(\n",
    "            loss=loss,\n",
    "            optimizer=optimizer)\n",
    "        \n",
    "        self.history = self.model.fit(x_t, y_t, \n",
    "                    epochs = epochs, \n",
    "                    batch_size= 64, \n",
    "                    verbose = 0)\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.y_scaler.inverse_transform(\n",
    "            self.model.predict(self.x_scaler.transform(\n",
    "                self.poly.transform(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_atf():\n",
    "    _list = []\n",
    "    _list.append(PreProcess(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)), standardize=True))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=7), whitening=True))\n",
    "\n",
    "    _list.append(PreProcess(RandomForestRegressor(max_depth= 15, max_samples=0.8), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [256, 512]))\n",
    "\n",
    "    \n",
    "    return _list\n",
    "\n",
    "def model_at():\n",
    "    _list = []\n",
    "    _list.append(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=6), whitening=True))\n",
    "    \n",
    "    _list.append(PreProcess(RandomForestRegressor(), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [512, 1024]))\n",
    "    \n",
    "    return _list\n",
    "\n",
    "def model_list():\n",
    "    _list = []\n",
    "\n",
    "    _list.append(PreProcess(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)), standardize=True))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=4), whitening=True))\n",
    "\n",
    "    _list.append(PreProcess(RandomForestRegressor(), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [256, 512]))\n",
    "\n",
    "    \n",
    "    return _list\n",
    "\n",
    "\n",
    "def srf_models():\n",
    "    _list = []\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=2), whitening=True))\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=3), whitening=True))\n",
    "    return _list\n",
    "\n",
    "\n",
    "mdls_atf = model_atf()\n",
    "mdls_at = model_at()\n",
    "\n",
    "def ranges(df_train, df_test):\n",
    "    df_test = df_test[df_test.Din > 70]\n",
    "    df_test = df_test[df_test.W > 6]\n",
    "    df_test = df_test[df_test.W < 14]\n",
    "    df_test = df_test[df_test.Din < 180 ]\n",
    "    \n",
    "    return  df_train, df_test\n",
    "\n",
    "data_folder = \"../data/inductGR_350nm_200GHz/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello package\n",
      "hello package\n"
     ]
    }
   ],
   "source": [
    "# freq and turn dependent model\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors_atf = []\n",
    "\n",
    "freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder)\n",
    "freq, _, __, x_test, y_test, _ = models.load_data(data_folder, 6)\n",
    "x_test = np.c_[ [5.00075]*len(x_test), x_test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-19 14:38:39.508143: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-05-19 14:38:39.508163: W tensorflow/stream_executor/cuda/cuda_driver.cc:269] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-05-19 14:38:39.508181: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (cad62.icg): /proc/driver/nvidia/version does not exist\n",
      "2022-05-19 14:38:39.508313: I tensorflow/core/platform/cpu_feature_guard.cc:151] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "errors_atf.append(models.test_it(mdls_atf, freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "print(\"ATF\")\n",
    "models.error_to_csv(errors_atf)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ATF\n",
      "L, None, None, None, None, 919.94, 52.41, 262.90, 6.43, 188.35, 6.11, 281.80, 5.85, \n",
      "Q, None, None, None, None, 4503.30, 123.91, 332.17, 9.98, 188.36, 8.03, 335.95, 14.08, \n"
     ]
    }
   ],
   "source": [
    "# freq and turn dependent model\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors_atf = []\n",
    "\n",
    "freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder)\n",
    "freq, _, __, x_test, y_test, _ = models.load_data(data_folder, 6, filter=ranges)\n",
    "x_test = np.c_[ [5.00075]*len(x_test), x_test]\n",
    "errors_atf.append(models.test_it(mdls_atf, freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "print(\"ATF\")\n",
    "models.error_to_csv(errors_atf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__alpha is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT\n",
      "L, 100.00, 100.00, 717.16, 25.66, 10.16, 0.22, 346.95, 6.59, 188.35, 6.11, 19.02, 1.10, \n",
      "Q, 100.00, 100.00, 10305.60, 225.86, 10.17, 0.77, 388.21, 8.29, 188.36, 8.03, 24.21, 4.87, \n"
     ]
    }
   ],
   "source": [
    "# trun dependent model\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors_at = []\n",
    "\n",
    "freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder, 6, filter=ranges)\n",
    "errors_at.append(models.test_it(model_list(), freq, x_train, y_train, x_test, y_test))\n",
    "print(\"AT\")\n",
    "models.error_to_csv(errors_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder, 6, filter=ranges)\n",
    "mdls_at[0] = GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GPR  AllT\n",
    "mdls_at[0].fit(x_train, y_train)\n",
    "pred = mdls_at[0].predict(x_test)\n",
    "errors_at[0][0] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "mdls_at[1] = KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=0.1**2*kl.RBF() + 0.5**2*kl.RBF() + 0.25**2*kl.RBF() + 1e-5 * kl.RationalQuadratic())\n",
    "mdls_at[1].fit(x_train, y_train)\n",
    "pred = mdls_at[1].predict(x_test)\n",
    "errors_at[0][1] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AT\n",
      "L, 369.49, 13.26, 102.72, 54.82, 10.16, 0.22, 346.95, 6.59, 188.35, 6.11, 19.02, 1.10, \n",
      "Q, 277.15, 53.34, 113.93, 95.59, 10.17, 0.77, 388.21, 8.29, 188.36, 8.03, 24.21, 4.87, \n"
     ]
    }
   ],
   "source": [
    "print(\"AT\")\n",
    "models.error_to_csv(errors_at)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:5 out of the last 13 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1a4668790> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k1__constant_value is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 14 calls to <function Model.make_predict_function.<locals>.predict_function at 0x7fb1a5f6ca60> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "No SRF Filter\n",
      "N=1, L, 0.17, 0.05, 0.49, 0.17, 0.16, 0.05, 4.14, 1.36, 5.62, 1.14, 0.53, 0.16, \n",
      "N=1, Q, 0.77, 0.21, 5.48, 1.88, 0.57, 0.15, 12.33, 3.69, 18.65, 5.59, 2.48, 0.57, \n",
      "N=2, L, 0.12, 0.03, 0.50, 0.19, 0.11, 0.03, 4.65, 2.12, 6.33, 1.35, 0.88, 0.23, \n",
      "N=2, Q, 0.32, 0.12, 3.37, 1.54, 0.23, 0.06, 9.94, 3.43, 15.75, 4.83, 4.27, 0.71, \n",
      "N=3, L, 0.09, 0.03, 0.53, 0.20, 0.18, 0.04, 5.95, 2.22, 5.59, 1.41, 0.96, 0.26, \n",
      "N=3, Q, 0.31, 0.10, 2.75, 1.16, 0.32, 0.05, 12.57, 3.79, 10.68, 2.84, 8.81, 1.55, \n",
      "N=4, L, 0.10, 0.03, 0.82, 0.29, 0.15, 0.05, 8.43, 2.81, 8.65, 2.76, 1.97, 0.50, \n",
      "N=4, Q, 0.42, 0.10, 5.67, 0.72, 0.61, 0.12, 15.58, 4.29, 13.88, 3.38, 7.39, 1.73, \n",
      "N=5, L, 29.24, 1.55, 304.56, 13.03, 39.91, 1.96, 2097.18, 101.42, 2366.15, 112.67, 281.16, 14.37, \n",
      "N=5, Q, 28.54, 1.59, 306.66, 14.39, 40.72, 2.11, 2679.41, 137.80, 2794.11, 173.28, 277.70, 16.00, \n"
     ]
    }
   ],
   "source": [
    "#turn and freq independent @ 5GHz\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors = []\n",
    "\n",
    "for nt in range(1, 6):\n",
    "    freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder, 6, nt = nt)\n",
    "    errors.append(models.test_it(model_list(), freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "print(\"No SRF Filter\")\n",
    "models.error_to_csv(errors, line_headers = [f'N={nt}' for nt in range(1, 6)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__alpha is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SRF Filter\n",
      "N=1, L, 0.17, 0.05, 0.49, 0.17, 0.16, 0.05, 4.14, 1.36, 5.62, 1.14, 0.53, 0.16, \n",
      "N=1, Q, 0.77, 0.21, 5.48, 1.88, 0.57, 0.15, 12.33, 3.69, 18.65, 5.59, 2.48, 0.57, \n",
      "N=2, L, 0.12, 0.03, 0.50, 0.19, 0.11, 0.03, 4.65, 2.12, 6.33, 1.35, 0.88, 0.23, \n",
      "N=2, Q, 0.32, 0.12, 3.37, 1.54, 0.23, 0.06, 9.94, 3.43, 15.75, 4.83, 4.27, 0.71, \n",
      "N=3, L, 0.09, 0.03, 0.53, 0.20, 0.18, 0.04, 5.95, 2.22, 5.59, 1.41, 0.96, 0.26, \n",
      "N=3, Q, 0.31, 0.10, 2.75, 1.16, 0.32, 0.05, 12.57, 3.79, 10.68, 2.84, 8.81, 1.55, \n",
      "N=4, L, 0.10, 0.03, 0.84, 0.29, 0.16, 0.04, 6.08, 2.39, 5.09, 2.07, 2.11, 0.55, \n",
      "N=4, Q, 0.34, 0.08, 3.24, 0.85, 0.28, 0.08, 7.76, 3.01, 8.81, 2.26, 4.53, 1.53, \n",
      "N=5, L, 0.09, 0.04, 1.88, 0.50, 0.08, 0.05, 17.80, 6.55, 14.57, 5.24, 5.20, 0.89, \n",
      "N=5, Q, 0.17, 0.08, 8.02, 2.06, 0.21, 0.06, 23.31, 5.23, 18.05, 4.50, 38.95, 4.99, \n"
     ]
    }
   ],
   "source": [
    "#turn and freq independent @ 5GHz SRF > 6GHz\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "errors = []\n",
    "\n",
    "for nt in range(1, 6):\n",
    "    freq, x_train, y_train, x_test, y_test, _ = models.load_data(data_folder, 6, nt = nt, srf=7.0)\n",
    "    errors.append(models.test_it(model_list(), freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "print(\"SRF Filter\")\n",
    "models.error_to_csv(errors, line_headers = [f'N={nt}' for nt in range(1, 6)])\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace: 1\n",
      "Subspace: 2\n",
      "Subspace: 3\n",
      "Subspace: 4\n",
      "Subspace: 5\n",
      "SRF filter error\n",
      "N=1, SRF, 922.38, 563.74, 921.84, 563.76, \n",
      "N=2, SRF, 221.39, 76.67, 223.09, 76.64, \n",
      "N=3, SRF, 52.59, 8.00, 52.46, 7.98, \n",
      "N=4, SRF, 9.05, 3.15, 9.03, 3.46, \n",
      "N=5, SRF, 12.81, 3.49, 12.81, 3.48, \n"
     ]
    }
   ],
   "source": [
    "# SRF Filter at + 10GHz\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "srf_errors = []\n",
    "\n",
    "for nt in range(1, 6):\n",
    "    print(f\"Subspace: {nt}\")\n",
    "    freq, x_train, y_train, x_test, y_test, srf_data = models.load_data(data_folder, 6, nt=nt, n_samples=1000)    \n",
    "    srf_errors.append(models.test_it_srf(srf_models(), srf_data))\n",
    "\n",
    "print(\"SRF filter error\")\n",
    "models.error_to_csv(srf_errors, line_headers = [f'N={nt}' for nt in range(1, 6)], error_headers = ['SRF, '])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#turn and freq independent @ 5GHz SRF > 7GHz\n",
    "import pickle\n",
    "import em\n",
    "import importlib\n",
    "\n",
    "importlib.reload(models)\n",
    "\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "\n",
    "model = {}\n",
    "for nt in range(1, 6):\n",
    "    for f in range(204):\n",
    "        freq, x_train, y_train, x_test, y_test, srf_data = models.load_data(data_folder, f, nt = nt, srf=7.0, skip_test=True)\n",
    "        m = models.RBFInterpolatorModel(degree=4)\n",
    "        m.fit(x_train, y_train)\n",
    "        mdl = {\n",
    "            'freq_index': f,\n",
    "            'freq': freq[0],\n",
    "            'nt': nt,\n",
    "            'RBFmodel': m\n",
    "        }\n",
    "\n",
    "        model[(nt, f)] = mdl\n",
    "    \n",
    "    srf_m = models.RBFInterpolatorModel(degree=2)\n",
    "    srf_m.fit(srf_data[0], srf_data[1])        \n",
    "    srf_mdl = {\n",
    "            'srf_limit': 7,\n",
    "            'nt': nt,\n",
    "            'RBFmodel': srf_m\n",
    "    }\n",
    "    model[(nt, 'srf')] = srf_mdl\n",
    "\n",
    "\n",
    "model['inputs'] = ['Din', 'W']\n",
    "model['ouputs'] = em.COLUMNS_2P[1:]\n",
    "model['ranges'] = {'din': (70, 180), 'w': (6, 14), 'nt': (1,5), 'freq': (0, 200)}\n",
    "model['device'] = 'ind'\n",
    "model['key'] = {'nt': [1, 2, 3, 4 ,5], 'f':(0, 203)}\n",
    "\n",
    "with open(\"../PASSIVES_RBF_IND_5G_SRF7_200GHz_tmtt.model\",'wb') as outfile:\n",
    "    pickle.dump(model, outfile)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Copyright (C) 2022 Instituto de Telecomunicações & IMSE CSIC"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e5760e712c30506cacfbb8d55a91dfa6d917c7cae71b450333e4dc838792f2f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
