{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-05-17 14:29:13.772957: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-05-17 14:29:13.772985: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import sklearn.gaussian_process.kernels as kl\n",
    "\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from scipy.interpolate import RBFInterpolator\n",
    "from scipy.interpolate import NearestNDInterpolator\n",
    "from sklearn.gaussian_process import GaussianProcessRegressor\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "\n",
    "import models\n",
    "import em"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformer 0.65um \n",
    "\n",
    "<img src=\"../img/transf.png\" alt=\"drawing\" width=\"200\"/> \n",
    "\n",
    "\n",
    "Octagonal transformer in TSMC 65 um. 1_1T, 1_2T, 2_1T\n",
    "\n",
    "Before running this notebook make sure to [prepare](data_prepare_tmtt_transf.ipynb) the data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model definition\n",
    "class PreProcess():\n",
    "    def __init__(self, model, whitening = False, standardize = False) -> None:\n",
    "        self.model = model\n",
    "        self.x_scaler = StandardScaler() if standardize else None\n",
    "        self.pca = PCA(whiten=True) if whitening else None\n",
    "    \n",
    "    def fit(self, x_train, y_train):\n",
    "        if self.pca:\n",
    "            self.x_mean = np.mean(x_train, axis=0)\n",
    "            x_train = x_train - self.x_mean\n",
    "            x_train = self.pca.fit_transform(x_train)\n",
    "        elif self.x_scaler:\n",
    "            x_train = self.x_scaler.fit_transform(x_train)\n",
    "\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        if self.pca:\n",
    "            x = x - self.x_mean\n",
    "            x = self.pca.transform(x)\n",
    "        elif self.x_scaler:\n",
    "            x = self.x_scaler.transform(x)\n",
    "        \n",
    "        return self.model.predict(x)\n",
    "\n",
    "class RBFInterpolatorModel:\n",
    "    def __init__(self, degree=1) -> None:\n",
    "        self.degree = degree\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = RBFInterpolator(x_train, y_train, \n",
    "                     degree=self.degree, smoothing=0.00000001, neighbors=4000)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "class GaussianProcessRegressorModel:\n",
    "    def __init__(self, kernel) -> None:\n",
    "        self.model = GaussianProcessRegressor(kernel=kernel, alpha=1e-8)\n",
    "        \n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model.fit(x_train, y_train)\n",
    "\n",
    "    def predict(self, x):\n",
    "        return self.model.predict(x)\n",
    "\n",
    "\n",
    "class NearestNDInterpolatorModel:\n",
    "    def fit(self, x_train, y_train):\n",
    "        self.model = NearestNDInterpolator(x_train, y_train)\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.model(x_test)\n",
    "\n",
    "class ANNModel:\n",
    "    def __init__(self, layers = None, degree = 5) -> None:\n",
    "       \n",
    "        self.poly     = PolynomialFeatures(degree)\n",
    "        self.x_scaler = StandardScaler()\n",
    "        self.y_scaler = StandardScaler()\n",
    "        self.layers = layers if layers else [256, 512]\n",
    "\n",
    "    def fit(self, x_train, y_train):\n",
    "        x_t = self.poly.fit_transform(x_train)  \n",
    "        x_t = self.x_scaler.fit_transform(x_t)\n",
    "\n",
    "        y_t = self.y_scaler.fit_transform(y_train)\n",
    "\n",
    "        activation = 'relu'\n",
    "        output='linear'\n",
    "        epochs = 1000\n",
    "        loss=\"mse\" \n",
    "        optimizer = keras.optimizers.Adam(learning_rate=0.0001)\n",
    "\n",
    "\n",
    "        inputs = keras.Input(shape=(x_t.shape[1],), name='parameters')\n",
    "        \n",
    "        lay = inputs\n",
    "\n",
    "        for n in self.layers:\n",
    "            lay = keras.layers.Dense(n, activation=activation, \n",
    "               kernel_regularizer=keras.regularizers.L2(0.000001), \n",
    "               activity_regularizer=keras.regularizers.L2(0.001))(lay)\n",
    "\n",
    "        outputs = keras.layers.Dense(y_t.shape[1], activation=output, \n",
    "            kernel_regularizer=keras.regularizers.L2(0.000001))(lay)\n",
    "        \n",
    "        self.model = keras.Model(inputs=inputs, outputs=outputs)\n",
    "        self.model.compile(\n",
    "            loss=loss,\n",
    "            optimizer=optimizer)\n",
    "        \n",
    "        self.history = self.model.fit(x_t, y_t, \n",
    "                    epochs = epochs, \n",
    "                    batch_size= 64, \n",
    "                    verbose = 0)\n",
    "\n",
    "\n",
    "    def predict(self, x_test):\n",
    "        return self.y_scaler.inverse_transform(\n",
    "            self.model.predict(self.x_scaler.transform(\n",
    "                self.poly.transform(x_test))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def model_atf():\n",
    "    _list = []\n",
    "    _list.append(PreProcess(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)), standardize=True))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=7), whitening=True))\n",
    "\n",
    "    _list.append(PreProcess(RandomForestRegressor(max_depth= 15, max_samples=0.8), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [256, 512]))\n",
    "\n",
    "    \n",
    "    return _list\n",
    "\n",
    "def model_at():\n",
    "    _list = []\n",
    "    _list.append(PreProcess(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)), standardize=True))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=6), whitening=True))\n",
    "    \n",
    "    _list.append(PreProcess(RandomForestRegressor(), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [512, 1024]))\n",
    "    \n",
    "    return _list\n",
    "\n",
    "def model_list():\n",
    "    _list = []\n",
    "\n",
    "    _list.append(PreProcess(GaussianProcessRegressorModel(0.1**2 * kl.RationalQuadratic(length_scale=1e-8, alpha=1e-8) + 1**2*kl.RBF(length_scale=5)), standardize=True))\n",
    "\n",
    "    _list.append(KernelRidge(alpha = 0.00000000001, \n",
    "          kernel=1e-5 * kl.RationalQuadratic(length_scale=1e-5, alpha=1e-5) + 1e-5**1*kl.RBF(length_scale=30)))\n",
    "\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=4), whitening=True))\n",
    "\n",
    "    _list.append(PreProcess(RandomForestRegressor(), whitening=True))\n",
    "    \n",
    "    _list.append(NearestNDInterpolatorModel())\n",
    "    \n",
    "    _list.append(ANNModel(layers = [256, 512]))\n",
    "\n",
    "    \n",
    "    return _list\n",
    "\n",
    "\n",
    "def srf_models():\n",
    "    _list = []\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=2), whitening=True))\n",
    "    _list.append(PreProcess(RBFInterpolatorModel(degree=3), whitening=True))\n",
    "    return _list\n",
    "\n",
    "\n",
    "\n",
    "sub_spaces = [(1,1, \"\"), (1,2, \"\"),(2,1, \"\")]\n",
    "\n",
    "def ranges(df_train, df_test):\n",
    "    df_test = df_test[df_test.Dinp > 20]\n",
    "    df_test = df_test[df_test.Wp > 6]\n",
    "    df_test = df_test[df_test.Wp < 14]\n",
    "    df_test = df_test[df_test.Dinp < 180 ]\n",
    "    df_test = df_test[df_test.Dins > 20]\n",
    "    df_test = df_test[df_test.Ws > 6]\n",
    "    df_test = df_test[df_test.Ws < 14]\n",
    "    df_test = df_test[df_test.Dins < 180 ]\n",
    "\n",
    "    return  df_train, df_test\n",
    "\n",
    "def ranges_28(df_train, df_test):\n",
    "    df_test = df_test[df_test.Dinp > 20]\n",
    "    df_test = df_test[df_test.Wp > 6]\n",
    "    df_test = df_test[df_test.Wp < 14]\n",
    "    df_test = df_test[df_test.Dinp < 180 ]\n",
    "    df_test = df_test[df_test.Dins > 20]\n",
    "    df_test = df_test[df_test.Ws > 6]\n",
    "    df_test = df_test[df_test.Ws < 14]\n",
    "    df_test = df_test[df_test.Dins < 180 ]\n",
    "\n",
    "    df_test = df_test[df_test.freq < 28.5 ]\n",
    "    df_test = df_test[df_test.freq > 27.5 ]\n",
    "\n",
    "    return  df_train, df_test\n",
    "\n",
    "\n",
    "mdls_atf = model_atf()\n",
    "mdls_at = model_at()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(704304, 7) (65, 7)\n",
      "[ 41.001   2.      1.    130.      9.     95.      9.   ] [ 28.001   1.      1.    130.      7.     67.      8.   ]\n"
     ]
    }
   ],
   "source": [
    "# AllTF\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors_all_TF  = [[((None, None, None, None, None),(None, None, None, None, None),(None, None, None, None, None)) for _ in range(6)]]\n",
    "\n",
    "freq, x_train, y_train, x_test, y_test, srf_data = models.load_data(\"../data/transf_65nm/\", filter= ranges_28)\n",
    "\n",
    "print(x_train.shape, x_test.shape)\n",
    "print(x_train[0], x_test[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to allocate 3.61 TiB for an array with shape (704304, 704304) and data type float64\n"
     ]
    }
   ],
   "source": [
    "#GPR AllTF\n",
    "try:\n",
    "    mdls_atf[0].fit(x_train, y_train)\n",
    "    pred = mdls_atf[0].predict(x_test)\n",
    "    errors_all_TF[0][0] = em.mape_lq_diff(freq, pred, y_test)\n",
    "except MemoryError as error:\n",
    "    print(error, file= sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Unable to allocate 3.61 TiB for an array with shape (704304, 704304) and data type float64\n"
     ]
    }
   ],
   "source": [
    "#KR AllTF\n",
    "try:\n",
    "    mdls_atf[1].fit(x_train, y_train)\n",
    "    pred = mdls_atf[1].predict(x_test)\n",
    "    errors_all_TF[0][1] = em.mape_lq_diff(freq, pred, y_test)\n",
    "except MemoryError as error:\n",
    "    print(error, file= sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF AllTF \n",
    "# - degree 7 w 4000 neigbours over 12Hrs no results\n",
    "# moved to degree 6 and 2000 neigbours - Prediction resutls might differ, but are bad. \n",
    "# For the sake of argument is the same as this strategy is not recomended anyway.\n",
    "try:\n",
    "    mdls_atf[2].fit(x_train, y_train)\n",
    "    pred = mdls_atf[2].predict(x_test)\n",
    "    errors_all_TF[0][2] = em.mape_lq_diff(freq, pred, y_test)\n",
    "except MemoryError as error:\n",
    "    print(error, file= sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFR AllTF\n",
    "try:\n",
    "    mdls_atf[3].fit(x_train, y_train)\n",
    "    pred = mdls_atf[3].predict(x_test)\n",
    "    errors_all_TF[0][3] = em.mape_lq_diff(freq, pred, y_test)\n",
    "except MemoryError as error:\n",
    "    print(error, file= sys.stderr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NND AllTF\n",
    "mdls_atf[4].fit(x_train, y_train)\n",
    "pred = mdls_atf[4].predict(x_test)\n",
    "errors_all_TF[0][4] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-04-23 16:37:16.297885: W tensorflow/core/framework/cpu_allocator_impl.cc:82] Allocation of 2231235072 exceeds 10% of free system memory.\n"
     ]
    }
   ],
   "source": [
    "#ANN AllTF\n",
    "mdls_atf[5].fit(x_train, y_train)\n",
    "pred = mdls_atf[5].predict(x_test)\n",
    "errors_all_TF[0][5] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllTF\n",
      "Lp, None, None, None, None, 325.92, 86.75, 81.53, 8.33, 121.71, 42.49, 145.84, 5.82, \n",
      "Qp, None, None, None, None, 218.66, 103.63, 87.76, 17.81, 4734.25, 418.82, 184.71, 26.73, \n",
      "Ls, None, None, None, None, 10671.42, 303.86, 1815.32, 37.16, 6088.05, 139.35, 808.26, 22.17, \n",
      "Qs, None, None, None, None, 2263.12, 165.57, 2528.58, 58.84, 25199.16, 759.65, 925.00, 39.02, \n",
      "k, None, None, None, None, 1689.02, 235.61, 81.98, 9.88, 171.10, 53.16, 290.53, 14.69, \n"
     ]
    }
   ],
   "source": [
    "print(\"AllTF\")\n",
    "models.error_to_csv(errors_all_TF)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3504, 6)\n",
      "[  2   1 189   8 121   5]\n"
     ]
    }
   ],
   "source": [
    "# AllT\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors_all_T = [[((None, None, None, None, None),(None, None, None, None, None),(None, None, None, None, None)) for _ in range(6)]]\n",
    "\n",
    "freq, x_train, y_train, x_test, y_test, _ = models.load_data(\"../data/transf_65nm/\", 28,filter=ranges)\n",
    "print(x_train.shape)\n",
    "print(x_train[0])\n",
    "\n",
    "#errors_all_T.append(models.test_it(mdls_at, freq, x_train, y_train, x_test, y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/_gpr.py:610: ConvergenceWarning: lbfgs failed to converge (status=2):\n",
      "ABNORMAL_TERMINATION_IN_LNSRCH.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "  _check_optimize_result(\"lbfgs\", opt_res)\n",
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:420: ConvergenceWarning: The optimal value found for dimension 0 of parameter k1__k2__length_scale is close to the specified lower bound 1e-05. Decreasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n",
      "/home/nlourenco/.pyenv/.py38env/lib/python3.8/site-packages/sklearn/gaussian_process/kernels.py:430: ConvergenceWarning: The optimal value found for dimension 0 of parameter k2__k1__constant_value is close to the specified upper bound 100000.0. Increasing the bound and calling fit again may find a better value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "#GPR  AllT\n",
    "mdls_at[0].fit(x_train, y_train)\n",
    "pred = mdls_at[0].predict(x_test)\n",
    "errors_all_T[0][0] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kl' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [17]\u001b[0m, in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m#KR  AllT\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m kernel \u001b[39m=\u001b[39m \u001b[39m1e-5\u001b[39m \u001b[39m*\u001b[39m kl\u001b[39m.\u001b[39mRationalQuadratic(length_scale\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m, alpha\u001b[39m=\u001b[39m\u001b[39m1e-5\u001b[39m) \u001b[39m+\u001b[39m \u001b[39m1e-5\u001b[39m\u001b[39m*\u001b[39m\u001b[39m*\u001b[39m\u001b[39m1\u001b[39m\u001b[39m*\u001b[39mkl\u001b[39m.\u001b[39mRBF(length_scale\u001b[39m=\u001b[39m\u001b[39m30\u001b[39m)\n\u001b[1;32m      3\u001b[0m m \u001b[39m=\u001b[39m KernelRidge(alpha \u001b[39m=\u001b[39m \u001b[39m0.00000000001\u001b[39m, kernel\u001b[39m=\u001b[39mkernel)\n\u001b[1;32m      4\u001b[0m m\u001b[39m.\u001b[39mfit(x_train, y_train)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'kl' is not defined"
     ]
    }
   ],
   "source": [
    "#KR  AllT\n",
    "mdls_at[1].fit(x_train, y_train)\n",
    "pred = mdls_at[1].predict(x_test)\n",
    "errors_all_T[0][1] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RBF  AllT\n",
    "mdls_at[2].fit(x_train, y_train)\n",
    "pred = mdls_at[2].predict(x_test)\n",
    "errors_all_T[0][2] = em.mape_lq_diff(freq, pred, y_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "#RFR  AllT\n",
    "mdls_at[3].fit(x_train, y_train)\n",
    "pred = mdls_at[3].predict(x_test)\n",
    "errors_all_T[0][3] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "#NND  AllT\n",
    "mdls_at[4].fit(x_train, y_train)\n",
    "pred = mdls_at[4].predict(x_test)\n",
    "errors_all_T[0][4] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANN  AllT\n",
    "mdls_at[5].fit(x_train, y_train)\n",
    "pred = mdls_at[5].predict(x_test)\n",
    "errors_all_T[0][5] = em.mape_lq_diff(freq, pred, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AllT\n",
      "Lp, None, None, None, None, None, None, None, None, None, None, None, None, \n",
      "Qp, None, None, None, None, None, None, None, None, None, None, None, None, \n",
      "Ls, None, None, None, None, None, None, None, None, None, None, None, None, \n",
      "Qs, None, None, None, None, None, None, None, None, None, None, None, None, \n",
      "k, None, None, None, None, None, None, None, None, None, None, None, None, \n",
      "Lp, 15.90, 0.46, 18.91, 2.41, 8.37, 0.34, 27.17, 4.49, 121.71, 42.49, 12.67, 2.51, \n",
      "Qp, 17.50, 1.74, 200.71, 15.63, 8.69, 1.32, 58.15, 10.79, 4734.25, 418.82, 72.97, 10.99, \n",
      "Ls, 40.45, 1.31, 248.25, 6.40, 16.34, 0.72, 742.15, 18.02, 6088.05, 139.35, 597.58, 12.69, \n",
      "Qs, 42.54, 2.35, 190.05, 15.43, 16.92, 1.64, 774.93, 25.39, 25199.16, 759.65, 566.16, 16.33, \n",
      "k, 29.79, 0.84, 47.90, 3.22, 8.52, 0.41, 167.96, 8.35, 171.10, 53.16, 52.83, 2.91, \n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"AllT\")\n",
    "models.error_to_csv(errors_all_T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace: (1, 1, '')\n",
      "Subspace: (1, 2, '')\n",
      "Subspace: (2, 1, '')\n",
      "No SRF filter\n",
      "Np=1 Ns=1, Lp, 0.34, 0.13, 1.04, 0.22, 0.35, 0.15, 9.10, 2.28, 10.62, 3.61, 0.88, 0.35, \n",
      "Np=1 Ns=1, Qp, 6.99, 1.75, 4.86, 1.81, 3.31, 1.43, 14.47, 8.58, 21.78, 4.33, 18.11, 3.46, \n",
      "Np=1 Ns=1, Ls, 0.23, 0.08, 1.03, 0.31, 0.26, 0.08, 15.97, 2.92, 10.15, 4.22, 1.59, 0.57, \n",
      "Np=1 Ns=1, Qs, 2.68, 0.75, 12.32, 4.04, 2.40, 0.80, 20.50, 8.29, 12.80, 4.70, 12.63, 3.37, \n",
      "Np=1 Ns=1, k, 0.46, 0.22, 0.81, 0.25, 0.41, 0.16, 10.00, 3.39, 25.38, 9.02, 4.64, 1.11, \n",
      "Np=1 Ns=2, Lp, 13.73, 0.89, 30.06, 1.72, 9.07, 0.62, 32.79, 3.27, 151.58, 11.40, 11.24, 0.98, \n",
      "Np=1 Ns=2, Qp, 15.66, 2.82, 31.44, 3.99, 10.81, 2.11, 235.22, 23.24, 167.15, 20.39, 81.36, 7.33, \n",
      "Np=1 Ns=2, Ls, 27.26, 1.55, 57.35, 3.11, 17.92, 1.12, 69.67, 8.75, 258.33, 20.09, 31.75, 2.37, \n",
      "Np=1 Ns=2, Qs, 28.21, 2.97, 57.39, 5.00, 19.06, 2.76, 314.74, 27.08, 355.21, 27.44, 109.77, 9.82, \n",
      "Np=1 Ns=2, k, 6.23, 0.59, 17.56, 1.28, 3.93, 0.44, 15.34, 5.68, 280.66, 24.72, 5.03, 1.22, \n",
      "Np=2 Ns=1, Lp, 1.09, 0.34, 1.21, 0.41, 0.75, 0.36, 22.78, 8.98, 40.98, 15.40, 5.93, 2.24, \n",
      "Np=2 Ns=1, Qp, 2.89, 1.01, 4.20, 1.29, 3.55, 1.02, 32.49, 11.76, 181.10, 24.22, 35.86, 8.88, \n",
      "Np=2 Ns=1, Ls, 47.50, 2.25, 25.98, 1.55, 39.07, 1.96, 1355.58, 62.08, 848.32, 57.74, 224.14, 11.48, \n",
      "Np=2 Ns=1, Qs, 49.66, 3.18, 27.72, 3.27, 40.89, 2.79, 1371.57, 69.57, 1300.62, 72.00, 230.62, 15.05, \n",
      "Np=2 Ns=1, k, 38.31, 1.83, 16.50, 1.08, 28.32, 1.46, 87.88, 12.61, 71.78, 16.43, 45.52, 3.76, \n"
     ]
    }
   ],
   "source": [
    "# NO SRF\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors = []\n",
    "\n",
    "for subsp in sub_spaces:\n",
    "    print(f\"Subspace: {subsp}\")\n",
    "    freq, x_train, y_train, x_test, y_test, _ = models.load_data(\"../data/transf_65nm/\", 28, nt=subsp, n_samples=1000, filter=ranges)\n",
    "    errors.append(models.test_it(model_list(), freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "print(\"No SRF filter\")\n",
    "models.error_to_csv(errors,line_headers = [f'Np={nt[0]} Ns={nt[1]}' for nt in sub_spaces])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace: (1, 1, '')\n",
      "Subspace: (1, 2, '')\n",
      "Subspace: (2, 1, '')\n",
      "SRF filter\n",
      "Np=1 Ns=1, Lp, 0.34, 0.13, 1.04, 0.22, 0.35, 0.15, 9.10, 2.28, 10.62, 3.61, 0.88, 0.35, \n",
      "Np=1 Ns=1, Qp, 6.99, 1.75, 4.86, 1.81, 3.31, 1.43, 14.47, 8.58, 21.78, 4.33, 18.11, 3.46, \n",
      "Np=1 Ns=1, Ls, 0.23, 0.08, 1.03, 0.31, 0.26, 0.08, 15.97, 2.92, 10.15, 4.22, 1.59, 0.57, \n",
      "Np=1 Ns=1, Qs, 2.68, 0.75, 12.32, 4.04, 2.40, 0.80, 20.50, 8.29, 12.80, 4.70, 12.63, 3.37, \n",
      "Np=1 Ns=1, k, 0.46, 0.22, 0.81, 0.25, 0.41, 0.16, 10.00, 3.39, 25.38, 9.02, 4.64, 1.11, \n",
      "Np=1 Ns=2, Lp, 0.62, 0.17, 0.52, 0.16, 0.65, 0.18, 5.16, 1.98, 6.22, 2.54, 2.00, 0.60, \n",
      "Np=1 Ns=2, Qp, 5.22, 1.91, 6.04, 2.37, 4.96, 1.86, 22.09, 11.81, 27.33, 9.10, 6.44, 2.99, \n",
      "Np=1 Ns=2, Ls, 0.47, 0.15, 0.44, 0.24, 0.45, 0.14, 12.69, 5.53, 16.20, 5.92, 1.97, 0.72, \n",
      "Np=1 Ns=2, Qs, 3.00, 0.94, 4.03, 1.83, 4.40, 1.27, 17.95, 11.38, 15.69, 6.09, 14.22, 3.62, \n",
      "Np=1 Ns=2, k, 0.69, 0.26, 1.16, 0.47, 0.50, 0.16, 11.93, 5.62, 29.01, 12.19, 5.19, 1.50, \n",
      "Np=2 Ns=1, Lp, 0.14, 0.07, 0.31, 0.21, 0.03, 0.03, 1.87, 1.34, 11.61, 7.22, 2.24, 2.19, \n",
      "Np=2 Ns=1, Qp, 0.65, 0.55, 0.89, 0.53, 0.39, 0.23, 13.34, 12.91, 7.21, 4.90, 4.79, 3.42, \n",
      "Np=2 Ns=1, Ls, 0.05, 0.03, 1.08, 0.93, 0.29, 0.19, 6.33, 4.89, 9.37, 5.05, 0.56, 0.48, \n",
      "Np=2 Ns=1, Qs, 2.14, 1.31, 7.07, 5.24, 3.94, 2.13, 5.67, 4.53, 7.96, 4.96, 4.30, 4.04, \n",
      "Np=2 Ns=1, k, 0.74, 0.59, 1.09, 0.79, 0.43, 0.31, 13.55, 9.34, 12.26, 9.94, 0.24, 0.22, \n"
     ]
    }
   ],
   "source": [
    "# SRF Filter at + 10GHz\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "errors = []\n",
    "\n",
    "for subsp in sub_spaces:\n",
    "    print(f\"Subspace: {subsp}\")\n",
    "    freq, x_train, y_train, x_test, y_test, _ = models.load_data(\"../data/transf_65nm/\", 28, srf=38, nt=subsp, n_samples=1000, filter=ranges)\n",
    "    errors.append(models.test_it(model_list(), freq, x_train, y_train, x_test, y_test))\n",
    "\n",
    "\n",
    "print(\"SRF filter\")\n",
    "models.error_to_csv(errors,line_headers = [f'Np={nt[0]} Ns={nt[1]}' for nt in sub_spaces])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Subspace: (1, 1, '')\n",
      "Subspace: (1, 2, '')\n",
      "Subspace: (2, 1, '')\n",
      "SRF filter error\n",
      "Np=1 Ns=1, SRFp, 1.72, 0.32, 1.50, 0.32, \n",
      "Np=1 Ns=1, SRFs, 6.00, 1.83, 5.99, 1.81, \n",
      "Np=1 Ns=2, SRFp, 58.93, 15.54, 58.90, 15.53, \n",
      "Np=1 Ns=2, SRFs, 1.46, 0.58, 1.60, 0.58, \n",
      "Np=2 Ns=1, SRFp, 2.99, 1.15, 3.00, 1.14, \n",
      "Np=2 Ns=1, SRFs, 82.98, 14.56, 85.31, 14.81, \n"
     ]
    }
   ],
   "source": [
    "# SRF Filter at + 10GHz\n",
    "np.random.seed(1234)\n",
    "tf.random.set_seed(1234)\n",
    "srf_errors = []\n",
    "\n",
    "\n",
    "for subsp in sub_spaces:\n",
    "    print(f\"Subspace: {subsp}\")\n",
    "    freq, x_train, y_train, x_test, y_test, srf_data = models.load_data(\"../data/transf_65nm/\", 28, srf=38, nt=subsp, n_samples=1000, filter=ranges)    \n",
    "    srf_errors.append(models.test_it_srf(srf_models(), srf_data))\n",
    "\n",
    "print(\"SRF filter error\")\n",
    "models.error_to_csv(srf_errors, line_headers = [f'Np={nt[0]} Ns={nt[1]}' for nt in sub_spaces], error_headers = ['SRFp, ', 'SRFs, '])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "0e5760e712c30506cacfbb8d55a91dfa6d917c7cae71b450333e4dc838792f2f"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
